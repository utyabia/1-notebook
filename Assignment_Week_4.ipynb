{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv0DWtVbQq8SKvAk6Xg6wf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utyabia/1-notebook/blob/main/Assignment_Week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQscIsDESrn9",
        "outputId": "f37b346c-9d70-41fe-a889-cf1eb399c856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lead_source                 128\n",
            "industry                    134\n",
            "number_of_courses_viewed      0\n",
            "annual_income               181\n",
            "employment_status           100\n",
            "location                     63\n",
            "interaction_count             0\n",
            "lead_score                    0\n",
            "converted                     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Bank Marketing dataset.txt')\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values\n",
        "df['industry'] = df['industry'].fillna('NA')\n",
        "df['employment_status'] = df['employment_status'].fillna('NA')\n",
        "df['annual_income'] = df['annual_income'].fillna(0.0)\n",
        "df['lead_source'] = df['lead_source'].fillna('NA')\n",
        "df['location'] = df['location'].fillna('NA')"
      ],
      "metadata": {
        "id": "uCRXrE7ZS4n2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2 of total"
      ],
      "metadata": {
        "id": "UsMRp9ZYS8xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "numerical = ['lead_score', 'number_of_courses_viewed', 'interaction_count', 'annual_income']\n",
        "y_train = df_train['converted'].values\n",
        "\n",
        "auc_scores = {}\n",
        "\n",
        "for col in numerical:\n",
        "    auc = roc_auc_score(y_train, df_train[col])\n",
        "    if auc < 0.5:\n",
        "        auc = roc_auc_score(y_train, -df_train[col])\n",
        "    auc_scores[col] = auc\n",
        "\n",
        "auc_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf_x1abfTAyf",
        "outputId": "9b27e51b-7b77-47d4-8376-716af7a616ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lead_score': np.float64(0.6144993577250176),\n",
              " 'number_of_courses_viewed': np.float64(0.7635680590007088),\n",
              " 'interaction_count': np.float64(0.738270176293409),\n",
              " 'annual_income': np.float64(0.5519578313253012)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "train_dicts = df_train.drop(columns=['converted']).to_dict(orient='records')\n",
        "val_dicts = df_val.drop(columns=['converted']).to_dict(orient='records')\n",
        "\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "X_val = dv.transform(val_dicts)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "auc = roc_auc_score(df_val['converted'], y_pred)\n",
        "print(round(auc, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "1e4V4ORXTsvM",
        "outputId": "c8562b5d-5fbe-42c0-c6c6-d3a7f5ed9df8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1554583479.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ea103d6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2 of total"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b05a8930",
        "outputId": "764e9a74-1c37-4d02-8926-0e78eb96a14b"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "train_dicts = df_train.drop(columns=['converted']).to_dict(orient='records')\n",
        "val_dicts = df_val.drop(columns=['converted']).to_dict(orient='records')\n",
        "\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "X_val = dv.transform(val_dicts)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict_proba(X_val)[:, 1]\n",
        "auc = roc_auc_score(df_val['converted'], y_pred)\n",
        "print(f'AUC on validation set: {round(auc, 3)}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC on validation set: 0.817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4c5238",
        "outputId": "245af012-b09f-448e-f357-6f0c733db4a0"
      },
      "source": [
        "test_dicts = df_test.drop(columns=['converted']).to_dict(orient='records')\n",
        "X_test = dv.transform(test_dicts)\n",
        "\n",
        "y_pred_test = model.predict_proba(X_test)[:, 1]\n",
        "auc_test = roc_auc_score(df_test['converted'], y_pred_test)\n",
        "print(f'AUC on test set: {round(auc_test, 3)}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC on test set: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4c910bf",
        "outputId": "306796e4-a24a-4917-e435-fe1b2a342db1"
      },
      "source": [
        "print(\"Missing values in df_train:\")\n",
        "print(df_train.isnull().sum())\n",
        "print(\"\\nMissing values in df_val:\")\n",
        "print(df_val.isnull().sum())\n",
        "print(\"\\nMissing values in df_test:\")\n",
        "print(df_test.isnull().sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in df_train:\n",
            "lead_source                 75\n",
            "industry                     0\n",
            "number_of_courses_viewed     0\n",
            "annual_income                0\n",
            "employment_status            0\n",
            "location                    37\n",
            "interaction_count            0\n",
            "lead_score                   0\n",
            "converted                    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in df_val:\n",
            "lead_source                 22\n",
            "industry                     0\n",
            "number_of_courses_viewed     0\n",
            "annual_income                0\n",
            "employment_status            0\n",
            "location                    13\n",
            "interaction_count            0\n",
            "lead_score                   0\n",
            "converted                    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in df_test:\n",
            "lead_source                 31\n",
            "industry                     0\n",
            "number_of_courses_viewed     0\n",
            "annual_income                0\n",
            "employment_status            0\n",
            "location                    13\n",
            "interaction_count            0\n",
            "lead_score                   0\n",
            "converted                    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3: Precision-Recall intersection\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "y_val_true = df_val['converted'].values\n",
        "y_pred_val = model.predict_proba(X_val)[:, 1] # Get validation predictions\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_bin = (y_pred_val >= t).astype(int)\n",
        "    precisions.append(precision_score(y_val_true, y_pred_bin, zero_division=1))\n",
        "    recalls.append(recall_score(y_val_true, y_pred_bin))\n",
        "\n",
        "# Find intersection\n",
        "intersection_threshold = None\n",
        "for i, t in enumerate(thresholds):\n",
        "    if abs(precisions[i] - recalls[i]) < 0.005:  # small tolerance\n",
        "        intersection_threshold = t\n",
        "        break\n",
        "\n",
        "print(f\"Q3 - Precision/Recall intersection at threshold: {intersection_threshold:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_bVORv-V0wy",
        "outputId": "118450ad-5dce-4a9d-bc07-8ddb75087cde"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q3 - Precision/Recall intersection at threshold: 0.640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4: Max F1 threshold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_scores = []\n",
        "for t in thresholds:\n",
        "    y_pred_bin = (y_pred_val >= t).astype(int)\n",
        "    f1_scores.append(f1_score(y_val_true, y_pred_bin))\n",
        "\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "print(f\"Q4 - Best F1 at threshold: {best_threshold:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1vkqrGqWI_M",
        "outputId": "2fb65ae5-6a0c-4ce8-ad36-427bafaa8a54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q4 - Best F1 at threshold: 0.570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5: 5-Fold CV\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "scores = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(df_full_train):\n",
        "    df_fold_train = df_full_train.iloc[train_idx]\n",
        "    df_fold_val = df_full_train.iloc[val_idx]\n",
        "\n",
        "    train_dicts = df_fold_train.to_dict(orient='records')\n",
        "    val_dicts = df_fold_val.to_dict(orient='records')\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    X_fold_train = dv.fit_transform(train_dicts)\n",
        "    X_fold_val = dv.transform(val_dicts)\n",
        "\n",
        "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "    model.fit(X_fold_train, df_fold_train['converted'])\n",
        "\n",
        "    y_pred_fold = model.predict_proba(X_fold_val)[:, 1]\n",
        "    auc = roc_auc_score(df_fold_val['converted'], y_pred_fold)\n",
        "    scores.append(auc)\n",
        "\n",
        "print(f\"Q5 - CV Scores: {np.round(scores, 4)}\")\n",
        "print(f\"Mean: {np.mean(scores):.3f}, Std: {np.std(scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLnM10gBWU8r",
        "outputId": "14b4e8f6-f92f-4a35-9bc4-e4b6294f1d53"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q5 - CV Scores: [0.8688 0.9217 0.8434 0.8422 0.9026]\n",
            "Mean: 0.876, Std: 0.0318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6: Hyperparameter tuning\n",
        "C_values = [0.000001, 0.001, 1]\n",
        "results = []\n",
        "\n",
        "for C in C_values:\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(df_full_train):\n",
        "        df_fold_train = df_full_train.iloc[train_idx]\n",
        "        df_fold_val = df_full_train.iloc[val_idx]\n",
        "\n",
        "        train_dicts = df_fold_train.to_dict(orient='records')\n",
        "        val_dicts = df_fold_val.to_dict(orient='records')\n",
        "\n",
        "        dv = DictVectorizer(sparse=False)\n",
        "        X_fold_train = dv.fit_transform(train_dicts)\n",
        "        X_fold_val = dv.transform(val_dicts)\n",
        "\n",
        "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
        "        model.fit(X_fold_train, df_fold_train['converted'])\n",
        "\n",
        "        y_pred_fold = model.predict_proba(X_fold_val)[:, 1]\n",
        "        auc = roc_auc_score(df_fold_val['converted'], y_pred_fold)\n",
        "        scores.append(auc)\n",
        "\n",
        "    mean_score = np.mean(scores)\n",
        "    std_score = np.std(scores)\n",
        "    results.append((C, mean_score, std_score))\n",
        "    print(f\"C={C}: Mean={mean_score:.3f}, Std={std_score:.3f}\")\n",
        "\n",
        "# Find best C\n",
        "best_C = min(results, key=lambda x: (-x[1], x[2], x[0]))[0]  # max mean, min std, min C\n",
        "print(f\"Q6 - Best C: {best_C}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "110eut7WWwpk",
        "outputId": "a82eeb72-5e57-415c-856b-f04a8f629ed8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1e-06: Mean=0.561, Std=0.024\n",
            "C=0.001: Mean=0.926, Std=0.018\n",
            "C=1: Mean=0.876, Std=0.032\n",
            "Q6 - Best C: 0.001\n"
          ]
        }
      ]
    }
  ]
}